# ðŸ¤” What are ensemble methods?
---
Instead of just using one predictive model, why not use a bunch of classifiers and return the majority classification? That's what ensemble methods are.

As it turns out, this can improve the error rate a lot â€” to the extent that the different classifiers are independent and their error is better than random (a committee of clones is quite useless, and a committee of blinds is also useless).

![[Pasted image 20250206175020.png]][[Pasted image 20250206175542.png|Here is the formula for the error rate of an ensemble]] of $N$ independent classifiers with error rate $Îµ$.

# ðŸ‘œ Bagging

# ðŸš€ Boosting

# ðŸŒ² Random Forest
