“In addition, the study revealed that the beginning of the document is the most informative part for genre prediction, which means that the Transformer models are potent enough to only need a short part of a text to recognize a genre.” (Kuzman and Ljubešić, 2025, p. 562) (512 tokens in the beginning for BERT).

Idea: GPT with metadata

What size validation corpus?



Annotation methods (check Luo and others) (check X-GENRE annotation):

Tasks per annotator
Feasible # of annotations
Workflow? Excel?
Inter-annotator agreement method?
Find pre-annotated scientific genre corpus, find correspondence 



Check cost of GPT
Check required context length



Check articles that cite Kuzman or Kuzman 2025/2023/2022
Check citing Daradkeh, Daradkeh 2022 (metadata CNN)



together.ai free API key: c777bfa1ce2fe16defd682ff225d2027409e94d66c052060ff8ce668836e231f

